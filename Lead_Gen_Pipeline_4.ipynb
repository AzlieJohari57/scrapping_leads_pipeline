{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2c095eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "539d07dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 42 rows from ./Staging/Gold/Gold_Scrapped_Data_1.parquet\n",
      "(42, 14)\n"
     ]
    }
   ],
   "source": [
    "parquet_path = \"./Staging/Gold/Gold_Scrapped_Data_1.parquet\"\n",
    "if os.path.exists(parquet_path):\n",
    "    Gold_Scrapped_Data_1 = pd.read_parquet(parquet_path, engine=\"fastparquet\")\n",
    "    print(f\"Loaded {len(Gold_Scrapped_Data_1)} rows from {parquet_path}\")\n",
    "    print(Gold_Scrapped_Data_1.shape)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Parquet file not found at {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0aa42f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Leads = Gold_Scrapped_Data_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42d02d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UEN', 'ENTITY_NAME', 'Phones', 'PIC Source 1', 'Emails', 'Website', 'Facebook', 'LinkedIn', 'Instagram', 'TikTok', 'operational_street', 'operational_unit', 'operational_postal_code', 'operational_address']\n"
     ]
    }
   ],
   "source": [
    "print(New_Leads.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d95a0550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 14)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(New_Leads.shape)\n",
    "print(New_Leads[\"UEN\"].is_unique)\n",
    "\n",
    "# Handle unhashable types (e.g. lists) by converting to tuples for uniqueness check\n",
    "print(New_Leads[\"Phones\"].apply(lambda x: tuple(x) if isinstance(x, list) else x).is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1c0a42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>Phones</th>\n",
       "      <th>PIC Source 1</th>\n",
       "      <th>Emails</th>\n",
       "      <th>Website</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Instagram</th>\n",
       "      <th>TikTok</th>\n",
       "      <th>operational_street</th>\n",
       "      <th>operational_unit</th>\n",
       "      <th>operational_postal_code</th>\n",
       "      <th>operational_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52895287X</td>\n",
       "      <td>CHNG LI CHERN FOOD &amp; BEVERAGE</td>\n",
       "      <td>[+6564836187]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://hungrygowhere.com/singapore/chng_li_ch...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10 ANG MO KIO INDUSTRIAL PARK 2A AMK AUTOPOINT</td>\n",
       "      <td>01-21</td>\n",
       "      <td>568047</td>\n",
       "      <td>10 ANG MO KIO INDUSTRIAL PARK 2A AMK AUTOPOINT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201505039Z</td>\n",
       "      <td>WANTON PTE. LTD.</td>\n",
       "      <td>[+6562211336]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>[sup@wantonsg.com]</td>\n",
       "      <td>https://wantonsg.com/</td>\n",
       "      <td>[https://www.facebook.com/wanton.sg/]</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/wanton.sg/?hl=en]</td>\n",
       "      <td>None</td>\n",
       "      <td>458 RACE COURSE ROAD</td>\n",
       "      <td>None</td>\n",
       "      <td>218699</td>\n",
       "      <td>458 RACE COURSE ROAD Singapore 218699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201212824G</td>\n",
       "      <td>FOOD DISTRICT PTE. LTD.</td>\n",
       "      <td>[+6562550155]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1 SOPHIA ROAD ONE SOPHIA</td>\n",
       "      <td>01-52</td>\n",
       "      <td>228149</td>\n",
       "      <td>1 SOPHIA ROAD ONE SOPHIA 01-52 Singapore 228149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201334572W</td>\n",
       "      <td>8082 F&amp;B PTE. LTD.</td>\n",
       "      <td>[+6596882525]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>[8082fnbpl@gmail.com]</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://m.facebook.com/8082KOPITIAM/about/]</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/explore/locations/5...</td>\n",
       "      <td>None</td>\n",
       "      <td>21 BENOI SECTOR MAPLETREE BENOI LOGISTICS HUB</td>\n",
       "      <td>01-05</td>\n",
       "      <td>629853</td>\n",
       "      <td>21 BENOI SECTOR MAPLETREE BENOI LOGISTICS HUB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201621449E</td>\n",
       "      <td>KIMLY DIM SUM WEST PTE. LTD.</td>\n",
       "      <td>[+6562659515]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://kimlygroup.sg/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>13, WOODLANDS LINK</td>\n",
       "      <td>None</td>\n",
       "      <td>738725</td>\n",
       "      <td>13, WOODLANDS LINK Singapore 738725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UEN                    ENTITY_NAME         Phones PIC Source 1  \\\n",
       "0   52895287X  CHNG LI CHERN FOOD & BEVERAGE  [+6564836187]    RecordOwl   \n",
       "1  201505039Z               WANTON PTE. LTD.  [+6562211336]    RecordOwl   \n",
       "2  201212824G        FOOD DISTRICT PTE. LTD.  [+6562550155]    RecordOwl   \n",
       "3  201334572W             8082 F&B PTE. LTD.  [+6596882525]    RecordOwl   \n",
       "4  201621449E   KIMLY DIM SUM WEST PTE. LTD.  [+6562659515]    RecordOwl   \n",
       "\n",
       "                  Emails                                            Website  \\\n",
       "0                   None  https://hungrygowhere.com/singapore/chng_li_ch...   \n",
       "1     [sup@wantonsg.com]                              https://wantonsg.com/   \n",
       "2                   None                                               None   \n",
       "3  [8082fnbpl@gmail.com]                                               None   \n",
       "4                   None                             https://kimlygroup.sg/   \n",
       "\n",
       "                                       Facebook LinkedIn  \\\n",
       "0                                          None     None   \n",
       "1         [https://www.facebook.com/wanton.sg/]     None   \n",
       "2                                          None     None   \n",
       "3  [https://m.facebook.com/8082KOPITIAM/about/]     None   \n",
       "4                                          None     None   \n",
       "\n",
       "                                           Instagram TikTok  \\\n",
       "0                                               None   None   \n",
       "1       [https://www.instagram.com/wanton.sg/?hl=en]   None   \n",
       "2                                               None   None   \n",
       "3  [https://www.instagram.com/explore/locations/5...   None   \n",
       "4                                               None   None   \n",
       "\n",
       "                               operational_street operational_unit  \\\n",
       "0  10 ANG MO KIO INDUSTRIAL PARK 2A AMK AUTOPOINT            01-21   \n",
       "1                            458 RACE COURSE ROAD             None   \n",
       "2                        1 SOPHIA ROAD ONE SOPHIA            01-52   \n",
       "3   21 BENOI SECTOR MAPLETREE BENOI LOGISTICS HUB            01-05   \n",
       "4                              13, WOODLANDS LINK             None   \n",
       "\n",
       "  operational_postal_code                                operational_address  \n",
       "0                  568047  10 ANG MO KIO INDUSTRIAL PARK 2A AMK AUTOPOINT...  \n",
       "1                  218699              458 RACE COURSE ROAD Singapore 218699  \n",
       "2                  228149    1 SOPHIA ROAD ONE SOPHIA 01-52 Singapore 228149  \n",
       "3                  629853  21 BENOI SECTOR MAPLETREE BENOI LOGISTICS HUB ...  \n",
       "4                  738725                13, WOODLANDS LINK Singapore 738725  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Leads.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a126b4a3",
   "metadata": {},
   "source": [
    "### Restructure to MasterDB Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e06776fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads_format = pd.DataFrame(columns=[\n",
    "    \"ePOS Code\",\n",
    "    \"Company Code\",\n",
    "    \"Date\",\n",
    "    \"ACRA REGISTERED NAME\",\n",
    "    \"Brand/Deal Name/Business Name\",\n",
    "    \"Sub Domain Link (If Lead is already available in Backend) Fill only when EPOS client\",\n",
    "    \"Tele Sales or MR (For KPI - Internal)\",\n",
    "    \"Name of the Market Researcher\",\n",
    "    \"Original Source (Marketing)\",\n",
    "    \"Marketing Source (Do not fill anything if the leads are from Hubspot, EPOS clients)\",\n",
    "    \"Company Registration date / Date Established\",\n",
    "    \"Company Registration Number (UEN)\",\n",
    "    \"Primary SSIC Code\",\n",
    "    \"Secondary SSIC Code\",\n",
    "    \"Hubspot ID (Company)\",\n",
    "    \"Hubspot ID(Deal)\",\n",
    "    \"Hubspot ID(Contact)\",\n",
    "    \"Website URL\",\n",
    "    \"Business Type\",\n",
    "    \"Facebook Page\",\n",
    "    \"Instagram URL\",\n",
    "    \"Linkedin URL\",\n",
    "    \"Tik Tok URL\",\n",
    "    \"Ownership Type\",\n",
    "    \"Parent Industry Type\",\n",
    "    \"Industry Type\",\n",
    "    \"Sub Industry\",\n",
    "    \"Business model\",\n",
    "    \"Presence of Multiple Outlets\",\n",
    "    \"Number of Outlets (Write in #)\",\n",
    "    \"Region\",\n",
    "    \"Planning Area\",\n",
    "    \"Business Location Type\",\n",
    "    \"Registered Address (Block & Street)\",\n",
    "    \"Registered Address (Unit #)\",\n",
    "    \"Registered Address (Postal code)\",\n",
    "    \"Operational Address \\n(Block & Street)\",\n",
    "    \"Operational Address \\n(Unit #)\",\n",
    "    \"Operational Address \\n(Postal Code)\",\n",
    "    \"Operational Address Type\",\n",
    "    \"First Name\",\n",
    "    \"Last Name\",\n",
    "    \"PIC Name 1 Designation\",\n",
    "    \"PIC NAME 1 Contact Number\",\n",
    "    \"PIC 1 email address\",\n",
    "    \"PIC 1 Source\",\n",
    "    \"First Name 2\",\n",
    "    \"Last Name 2\",\n",
    "    \"PIC Name 2 Designation\",\n",
    "    \"PIC NAME 2 Contact Number\",\n",
    "    \"PIC 2 email address\",\n",
    "    \"PIC 2 Source\",\n",
    "    \"First Name 3\",\n",
    "    \"Last Name 3\",\n",
    "    \"PIC Name Designation 3\",\n",
    "    \"PIC NAME 3 Contact Number\",\n",
    "    \"PIC 3 email address\",\n",
    "    \"PIC 3 Source\",\n",
    "    \"FB/Insta/Tik Tok/Linkedin Contact\",\n",
    "    \"Current ePOS Client ?\",\n",
    "    \"If ePOS Client, which product they are using?\",\n",
    "    \"Is this deal part of the Gov List?\",\n",
    "    \"Source from Market Researcher\",\n",
    "    \"Contact Number from Lusha?\",\n",
    "    \"Phone number Verified ?\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449f2f2",
   "metadata": {},
   "source": [
    "### Mapping scrapped leads to Master DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "331b32ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Mapped: UEN → Company Registration Number (UEN)\n",
      "✓ Mapped: Phones → PIC NAME 1 Contact Number\n",
      "✓ Mapped: Emails → PIC 1 email address\n",
      "✓ Mapped: Website → Website URL\n",
      "✓ Mapped: Facebook → Facebook Page\n",
      "✓ Mapped: Instagram → Instagram URL\n",
      "✓ Mapped: TikTok → Tik Tok URL\n",
      "✓ Mapped: LinkedIn → Linkedin URL\n",
      "✓ Mapped: PIC Source 1 → PIC 1 Source\n",
      "✓ Mapped: operational_address → Operational Address \n",
      "(Block & Street)\n",
      "✓ Mapped: operational_unit → Operational Address \n",
      "(Unit #)\n",
      "✓ Mapped: operational_postal_code → Operational Address \n",
      "(Postal Code)\n"
     ]
    }
   ],
   "source": [
    "# Define mapping from RecordOwl_Leads -> Fresh_Leads_format\n",
    "cols_map = {\n",
    "    \"UEN\": \"Company Registration Number (UEN)\",\n",
    "    \"Phones\": \"PIC NAME 1 Contact Number\",\n",
    "    \"Emails\": \"PIC 1 email address\",\n",
    "    \"Website\": \"Website URL\",\n",
    "    \"Facebook\": \"Facebook Page\",\n",
    "    \"Instagram\": \"Instagram URL\",\n",
    "    \"TikTok\": \"Tik Tok URL\",\n",
    "    \"LinkedIn\": \"Linkedin URL\",\n",
    "    \"PIC Source 1\":\"PIC 1 Source\",\n",
    "    \"operational_address\": \"Operational Address \\n(Block & Street)\",\n",
    "    \"operational_unit\": \"Operational Address \\n(Unit #)\",\n",
    "    \"operational_postal_code\": \"Operational Address \\n(Postal Code)\",\n",
    "}\n",
    "\n",
    "# Columns that contain lists and need to be flattened (extract first element)\n",
    "# FIXED: Removed \"Phones\" because it contains strings, not lists\n",
    "list_columns = [\"Emails\", \"Facebook\", \"Instagram\", \"TikTok\", \"LinkedIn\"]\n",
    "\n",
    "# CRITICAL FIX: Initialize Fresh_Leads_format with the same number of rows as RecordOwl_Leads\n",
    "Fresh_Leads_format = Fresh_Leads_format.reindex(range(len(New_Leads)))\n",
    "\n",
    "# Fill Fresh_Leads_format using mapping\n",
    "for src_col, dest_col in cols_map.items():\n",
    "    if src_col in New_Leads.columns and dest_col in Fresh_Leads_format.columns:\n",
    "        # Check if column contains lists\n",
    "        if src_col in list_columns:\n",
    "            # Extract first element from list, handle None/NaN gracefully\n",
    "            Fresh_Leads_format[dest_col] = New_Leads[src_col].apply(\n",
    "                lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None\n",
    "            ).values\n",
    "        else:\n",
    "            # Direct mapping for non-list columns\n",
    "            Fresh_Leads_format[dest_col] = New_Leads[src_col].values\n",
    "        print(f\"✓ Mapped: {src_col} → {dest_col}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Skipped: {src_col} → {dest_col} (missing in one of the DataFrames)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97bcced1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Registration Number (UEN)</th>\n",
       "      <th>PIC NAME 1 Contact Number</th>\n",
       "      <th>PIC 1 Source</th>\n",
       "      <th>PIC 1 email address</th>\n",
       "      <th>Website URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52895287X</td>\n",
       "      <td>[+6564836187]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://hungrygowhere.com/singapore/chng_li_ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201505039Z</td>\n",
       "      <td>[+6562211336]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>sup@wantonsg.com</td>\n",
       "      <td>https://wantonsg.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201212824G</td>\n",
       "      <td>[+6562550155]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201334572W</td>\n",
       "      <td>[+6596882525]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>8082fnbpl@gmail.com</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201621449E</td>\n",
       "      <td>[+6562659515]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://kimlygroup.sg/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201818844M</td>\n",
       "      <td>[+6585288528]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>phovietnam.sg@gmail.com</td>\n",
       "      <td>https://phovietnam.sg/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53383118X</td>\n",
       "      <td>[+6580705986]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T17LL0782C</td>\n",
       "      <td>[+6587801998]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202007378D</td>\n",
       "      <td>[+6568072250]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/food-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202346258K</td>\n",
       "      <td>[+6596963939]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>201902852K</td>\n",
       "      <td>[+6590234137]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>http://www.quench.sg/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>201533054M</td>\n",
       "      <td>[+6581395952]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>hello@wildfireburgers.com</td>\n",
       "      <td>https://www.straitstimes.com/life/food/food-pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>201431834G</td>\n",
       "      <td>[+6567443022]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/food-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>53200683J</td>\n",
       "      <td>[+6592287073]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>48609500B</td>\n",
       "      <td>[+6562228202]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53387333M</td>\n",
       "      <td>[+6568722236]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53291761L</td>\n",
       "      <td>[+6582366396]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://thefragrancekitchen.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>201540883E</td>\n",
       "      <td>[+6565357777]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.ey.com/en_sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202323972G</td>\n",
       "      <td>[+6563968926]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>53468768K</td>\n",
       "      <td>[+6587924161]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://newpalanivilas.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>202235279H</td>\n",
       "      <td>[+6564248787]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://zf.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>201621437K</td>\n",
       "      <td>[+6563868081]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>53169707W</td>\n",
       "      <td>[+6590097762]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>53292316B</td>\n",
       "      <td>[+6568288885]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://parkhotelgroup.com/en/alexandra/aqua-luna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202315944E</td>\n",
       "      <td>[+6563861816]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/food-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>201601248H</td>\n",
       "      <td>[+6594567976]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53084879A</td>\n",
       "      <td>[+6596906606]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://misstamchiak.com/sean-kee-duck-rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>201309437N</td>\n",
       "      <td>[+6562968368]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>sales@aeris.group</td>\n",
       "      <td>https://aeris.com.sg/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>53265100J</td>\n",
       "      <td>[+6562275892]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53479115L</td>\n",
       "      <td>[+6598644724]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>201815072D</td>\n",
       "      <td>[+6581369961]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>53457383E</td>\n",
       "      <td>[+6598658891]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>201312040R</td>\n",
       "      <td>[+6567482436]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/others/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>200402181M</td>\n",
       "      <td>[+6563342628]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pumproomasia.com.sg/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>200207535E</td>\n",
       "      <td>[+6562859078]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>202011894W</td>\n",
       "      <td>[+6591679396]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/admin/o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>53463060W</td>\n",
       "      <td>[+6582368031]</td>\n",
       "      <td>RecordOwl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>202103738H</td>\n",
       "      <td>+6568162849</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>None</td>\n",
       "      <td>https://funtoast.com.sg/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>53500821W</td>\n",
       "      <td>+6598589289</td>\n",
       "      <td>Google</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>201534343H</td>\n",
       "      <td>+6565159888</td>\n",
       "      <td>Google</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>201205374H</td>\n",
       "      <td>+6562991326</td>\n",
       "      <td>Google</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>53384322K</td>\n",
       "      <td>+6583106459</td>\n",
       "      <td>Google</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company Registration Number (UEN) PIC NAME 1 Contact Number PIC 1 Source  \\\n",
       "0                          52895287X             [+6564836187]    RecordOwl   \n",
       "1                         201505039Z             [+6562211336]    RecordOwl   \n",
       "2                         201212824G             [+6562550155]    RecordOwl   \n",
       "3                         201334572W             [+6596882525]    RecordOwl   \n",
       "4                         201621449E             [+6562659515]    RecordOwl   \n",
       "5                         201818844M             [+6585288528]    RecordOwl   \n",
       "6                          53383118X             [+6580705986]    RecordOwl   \n",
       "7                         T17LL0782C             [+6587801998]    RecordOwl   \n",
       "8                         202007378D             [+6568072250]    RecordOwl   \n",
       "9                         202346258K             [+6596963939]    RecordOwl   \n",
       "10                        201902852K             [+6590234137]    RecordOwl   \n",
       "11                        201533054M             [+6581395952]    RecordOwl   \n",
       "12                        201431834G             [+6567443022]    RecordOwl   \n",
       "13                         53200683J             [+6592287073]    RecordOwl   \n",
       "14                         48609500B             [+6562228202]    RecordOwl   \n",
       "15                         53387333M             [+6568722236]    RecordOwl   \n",
       "16                         53291761L             [+6582366396]    RecordOwl   \n",
       "17                        201540883E             [+6565357777]    RecordOwl   \n",
       "18                        202323972G             [+6563968926]    RecordOwl   \n",
       "19                         53468768K             [+6587924161]    RecordOwl   \n",
       "20                        202235279H             [+6564248787]    RecordOwl   \n",
       "21                        201621437K             [+6563868081]    RecordOwl   \n",
       "22                         53169707W             [+6590097762]    RecordOwl   \n",
       "23                         53292316B             [+6568288885]    RecordOwl   \n",
       "24                        202315944E             [+6563861816]    RecordOwl   \n",
       "25                        201601248H             [+6594567976]    RecordOwl   \n",
       "26                         53084879A             [+6596906606]    RecordOwl   \n",
       "27                        201309437N             [+6562968368]    RecordOwl   \n",
       "28                         53265100J             [+6562275892]    RecordOwl   \n",
       "29                         53479115L             [+6598644724]    RecordOwl   \n",
       "30                        201815072D             [+6581369961]    RecordOwl   \n",
       "31                         53457383E             [+6598658891]    RecordOwl   \n",
       "32                        201312040R             [+6567482436]    RecordOwl   \n",
       "33                        200402181M             [+6563342628]    RecordOwl   \n",
       "34                        200207535E             [+6562859078]    RecordOwl   \n",
       "35                        202011894W             [+6591679396]    RecordOwl   \n",
       "36                         53463060W             [+6582368031]    RecordOwl   \n",
       "37                        202103738H               +6568162849     Facebook   \n",
       "38                         53500821W               +6598589289       Google   \n",
       "39                        201534343H               +6565159888       Google   \n",
       "40                        201205374H               +6562991326       Google   \n",
       "41                         53384322K               +6583106459       Google   \n",
       "\n",
       "          PIC 1 email address  \\\n",
       "0                        None   \n",
       "1            sup@wantonsg.com   \n",
       "2                        None   \n",
       "3         8082fnbpl@gmail.com   \n",
       "4                        None   \n",
       "5     phovietnam.sg@gmail.com   \n",
       "6                        None   \n",
       "7                        None   \n",
       "8                        None   \n",
       "9                        None   \n",
       "10                       None   \n",
       "11  hello@wildfireburgers.com   \n",
       "12                       None   \n",
       "13                       None   \n",
       "14                       None   \n",
       "15                       None   \n",
       "16                       None   \n",
       "17                       None   \n",
       "18                       None   \n",
       "19                       None   \n",
       "20                       None   \n",
       "21                       None   \n",
       "22                       None   \n",
       "23                       None   \n",
       "24                       None   \n",
       "25                       None   \n",
       "26                       None   \n",
       "27          sales@aeris.group   \n",
       "28                       None   \n",
       "29                       None   \n",
       "30                       None   \n",
       "31                       None   \n",
       "32                       None   \n",
       "33                       None   \n",
       "34                       None   \n",
       "35                       None   \n",
       "36                       None   \n",
       "37                       None   \n",
       "38                       None   \n",
       "39                       None   \n",
       "40                       None   \n",
       "41                       None   \n",
       "\n",
       "                                          Website URL  \n",
       "0   https://hungrygowhere.com/singapore/chng_li_ch...  \n",
       "1                               https://wantonsg.com/  \n",
       "2                                                None  \n",
       "3                                                None  \n",
       "4                              https://kimlygroup.sg/  \n",
       "5                              https://phovietnam.sg/  \n",
       "6                                                None  \n",
       "7                                                None  \n",
       "8   https://www.mycareersfuture.gov.sg/job/food-an...  \n",
       "9                                                None  \n",
       "10                              http://www.quench.sg/  \n",
       "11  https://www.straitstimes.com/life/food/food-pi...  \n",
       "12  https://www.mycareersfuture.gov.sg/job/food-an...  \n",
       "13                                               None  \n",
       "14                                               None  \n",
       "15                                               None  \n",
       "16                   https://thefragrancekitchen.com/  \n",
       "17                           https://www.ey.com/en_sg  \n",
       "18                                               None  \n",
       "19                        https://newpalanivilas.com/  \n",
       "20                                    https://zf.com/  \n",
       "21                                               None  \n",
       "22                                               None  \n",
       "23  https://parkhotelgroup.com/en/alexandra/aqua-luna  \n",
       "24  https://www.mycareersfuture.gov.sg/job/food-an...  \n",
       "25                                               None  \n",
       "26        https://misstamchiak.com/sean-kee-duck-rice  \n",
       "27                              https://aeris.com.sg/  \n",
       "28                                               None  \n",
       "29                                               None  \n",
       "30                                               None  \n",
       "31                                               None  \n",
       "32  https://www.mycareersfuture.gov.sg/job/others/...  \n",
       "33                       https://pumproomasia.com.sg/  \n",
       "34                                               None  \n",
       "35  https://www.mycareersfuture.gov.sg/job/admin/o...  \n",
       "36                                               None  \n",
       "37                           https://funtoast.com.sg/  \n",
       "38                                               None  \n",
       "39                                               None  \n",
       "40                                               None  \n",
       "41                                               None  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fresh_Leads_format[[\"Company Registration Number (UEN)\", \"PIC NAME 1 Contact Number\", \"PIC 1 Source\",\"PIC 1 email address\", \"Website URL\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6bf15",
   "metadata": {},
   "source": [
    "### Getting ACRA Data and Merging with SSIC Code Mapping & Generating Business Type Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"Acra_Data\"\n",
    "\n",
    "# Get all CSV file paths inside the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "# Read and combine all CSVs\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in csv_files), ignore_index=True)\n",
    "\n",
    "df.columns = df.columns.str.upper()\n",
    "\n",
    "acra_data = df[[\n",
    "    \"UEN\",\n",
    "    \"ENTITY_NAME\",\n",
    "    \"BUSINESS_CONSTITUTION_DESCRIPTION\",\n",
    "    \"ENTITY_TYPE_DESCRIPTION\",\n",
    "    \"ENTITY_STATUS_DESCRIPTION\",\n",
    "    \"REGISTRATION_INCORPORATION_DATE\",\n",
    "    \"PRIMARY_SSIC_CODE\",\n",
    "    \"SECONDARY_SSIC_CODE\",\n",
    "    \"UNIT_NO\",\n",
    "    \"LEVEL_NO\",\n",
    "    \"BUILDING_NAME\",\n",
    "    \"BLOCK\",\n",
    "    \"STREET_NAME\",\n",
    "    \"POSTAL_CODE\"\n",
    "]].copy()\n",
    "\n",
    "# Convert to proper data types\n",
    "acra_data['UEN'] = acra_data['UEN'].astype('string')\n",
    "acra_data['ENTITY_NAME'] = acra_data['ENTITY_NAME'].astype('string')\n",
    "acra_data['BUSINESS_CONSTITUTION_DESCRIPTION'] = acra_data['BUSINESS_CONSTITUTION_DESCRIPTION'].astype('string')\n",
    "acra_data['ENTITY_TYPE_DESCRIPTION'] = acra_data['ENTITY_TYPE_DESCRIPTION'].astype('string')\n",
    "acra_data['ENTITY_STATUS_DESCRIPTION'] = acra_data['ENTITY_STATUS_DESCRIPTION'].astype('string')\n",
    "acra_data['BLOCK'] = acra_data['BLOCK'].astype('string')\n",
    "acra_data['STREET_NAME'] = acra_data['STREET_NAME'].astype('string')\n",
    "acra_data['POSTAL_CODE'] = acra_data['POSTAL_CODE'].astype('string')\n",
    "acra_data['UNIT_NO'] = acra_data['UNIT_NO'].astype('string')\n",
    "acra_data['LEVEL_NO'] = acra_data['LEVEL_NO'].astype('string')\n",
    "acra_data['BUILDING_NAME'] = acra_data['BUILDING_NAME'].astype('string')\n",
    "acra_data['PRIMARY_SSIC_CODE'] = pd.to_numeric(acra_data['PRIMARY_SSIC_CODE'], errors='coerce')\n",
    "acra_data['SECONDARY_SSIC_CODE'] = pd.to_numeric(acra_data['SECONDARY_SSIC_CODE'], errors='coerce')\n",
    "\n",
    "# Date column\n",
    "acra_data['REGISTRATION_INCORPORATION_DATE'] = pd.to_datetime(acra_data['REGISTRATION_INCORPORATION_DATE'], errors='coerce')\n",
    "\n",
    "# Clean string columns\n",
    "for col in ['UEN', 'ENTITY_NAME', 'BUSINESS_CONSTITUTION_DESCRIPTION', 'ENTITY_TYPE_DESCRIPTION', \n",
    "            'ENTITY_STATUS_DESCRIPTION', 'BLOCK', 'STREET_NAME', 'POSTAL_CODE', 'UNIT_NO', 'LEVEL_NO', 'BUILDING_NAME']:\n",
    "    acra_data[col] = acra_data[col].fillna('').str.strip().str.replace(r'\\s+', ' ', regex=True).str.upper()\n",
    "\n",
    "acra_data.replace(['NA', 'N/A', '-', ''], np.nan, inplace=True)\n",
    "acra_data['REGISTRATION_INCORPORATION_DATE'] = acra_data['REGISTRATION_INCORPORATION_DATE'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Filter only live entities\n",
    "acra_data = acra_data[acra_data['ENTITY_STATUS_DESCRIPTION'].isin(['LIVE COMPANY', 'LIVE'])].reset_index(drop=True)\n",
    "\n",
    "# Exclude specific PRIMARY_SSIC_CODE values\n",
    "exclude_codes = [46900, 47719, 47749, 47539, 47536, 56123, 10711, 10712, 10719, 10732, 10733, 93209]\n",
    "acra_data = acra_data[~acra_data['PRIMARY_SSIC_CODE'].isin(exclude_codes)].reset_index(drop=True)\n",
    "\n",
    "# Classify BUSINESS_TYPE - Based on age + ownership type only\n",
    "reg_date = pd.to_datetime(acra_data['REGISTRATION_INCORPORATION_DATE'], format='%d-%m-%Y', errors='coerce', dayfirst=True)\n",
    "company_age_years = (pd.Timestamp.today() - reg_date).dt.days / 365.25\n",
    "ownership_type = acra_data['ENTITY_TYPE_DESCRIPTION'].astype(str)\n",
    "\n",
    "acra_data['BUSINESS_TYPE'] = np.nan\n",
    "\n",
    "# Rule 1: age > 3 AND (LOCAL COMPANY | LLP | SOLE PROPRIETORSHIP) → SME\n",
    "mask = (company_age_years > 3) & ownership_type.str.contains('LOCAL COMPANY|LIMITED LIABILITY PARTNERSHIP|SOLE PROPRIETORSHIP/ PARTNERSHIP', case=False, na=False)\n",
    "acra_data.loc[mask, 'BUSINESS_TYPE'] = 'SME'\n",
    "\n",
    "# Rule 2: age > 5 AND FOREIGN COMPANY BRANCH → Large Enterprise\n",
    "mask = (company_age_years > 5) & ownership_type.str.contains('FOREIGN COMPANY BRANCH', case=False, na=False) & acra_data['BUSINESS_TYPE'].isna()\n",
    "acra_data.loc[mask, 'BUSINESS_TYPE'] = 'Large Enterprise'\n",
    "\n",
    "# Rule 3: age > 5 AND (LOCAL COMPANY | LLP) → Franchise\n",
    "mask = (company_age_years > 5) & ownership_type.str.contains('LOCAL COMPANY|LIMITED LIABILITY PARTNERSHIP', case=False, na=False) & acra_data['BUSINESS_TYPE'].isna()\n",
    "acra_data.loc[mask, 'BUSINESS_TYPE'] = 'Franchise'\n",
    "\n",
    "# Rule 4: age < 5 AND SOLE PROPRIETORSHIP → Startup\n",
    "mask = (company_age_years < 5) & ownership_type.str.contains('SOLE PROPRIETORSHIP/ PARTNERSHIP', case=False, na=False) & acra_data['BUSINESS_TYPE'].isna()\n",
    "acra_data.loc[mask, 'BUSINESS_TYPE'] = 'Startbud'\n",
    "\n",
    "# Fallback rules based on age only\n",
    "# Startup: Age ≤ 4\n",
    "# SME: Age 5–10\n",
    "# Large Enterprise: Age ≥ 11 OR (Foreign Company Branch with Age ≥ 7)\n",
    "unclassified = acra_data['BUSINESS_TYPE'].isna()\n",
    "acra_data.loc[unclassified & (company_age_years >= 11), 'BUSINESS_TYPE'] = 'Large Enterprise'\n",
    "acra_data.loc[unclassified & (company_age_years >= 7) & ownership_type.str.contains('FOREIGN COMPANY BRANCH', case=False, na=False), 'BUSINESS_TYPE'] = 'Large Enterprise'\n",
    "acra_data.loc[unclassified & (company_age_years >= 5) & (company_age_years <= 10) & acra_data['BUSINESS_TYPE'].isna(), 'BUSINESS_TYPE'] = 'SME'\n",
    "acra_data.loc[unclassified & (company_age_years <= 4) & acra_data['BUSINESS_TYPE'].isna(), 'BUSINESS_TYPE'] = 'Startbud'\n",
    "\n",
    "# Getting SSIC Code\n",
    "file_path = \"./SSIC_Code/mapped_ssic_code.xlsx\"\n",
    "mapped_ssic_code = pd.read_excel(file_path)\n",
    "mapped_ssic_code.columns = mapped_ssic_code.columns.str.strip().str.upper().str.replace(\" \", \"_\")\n",
    "columns_to_keep = [\"PARENT_INDUSTRY\", \"INDUSTRY_TYPE\", \"SUB_INDUSTRY\", \"SSIC_CODES\", \"DESCRIPTION\"]\n",
    "mapped_ssic_code = mapped_ssic_code[columns_to_keep].copy()\n",
    "mapped_ssic_code[\"SSIC_CODES\"] = pd.to_numeric(mapped_ssic_code[\"SSIC_CODES\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "text_cols = [\"PARENT_INDUSTRY\", \"INDUSTRY_TYPE\", \"SUB_INDUSTRY\", \"DESCRIPTION\"]\n",
    "mapped_ssic_code[text_cols] = mapped_ssic_code[text_cols].apply(lambda col: col.astype(str).str.strip().str.title())\n",
    "mapped_ssic_code = mapped_ssic_code.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Merging\n",
    "acra_data[\"PRIMARY_SSIC_CODE\"] = pd.to_numeric(acra_data[\"PRIMARY_SSIC_CODE\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "acra_data[\"SECONDARY_SSIC_CODE\"] = pd.to_numeric(acra_data[\"SECONDARY_SSIC_CODE\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "acra_data_mapped = acra_data.merge(mapped_ssic_code, how=\"left\", left_on=\"PRIMARY_SSIC_CODE\", right_on=\"SSIC_CODES\")\n",
    "acra_data_mapped = acra_data_mapped.drop(columns=[\"SSIC_CODES\"], errors=\"ignore\")\n",
    "\n",
    "print(\"\\n✅ ACRA Business Type classification completed!\")\n",
    "print(f\"\\nBusiness Type distribution:\\n{acra_data_mapped['BUSINESS_TYPE'].value_counts(dropna=False)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95860f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "acra_data_mapped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958863e2",
   "metadata": {},
   "source": [
    "### Mapping Leads with ACRA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5cfd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with ACRA data\n",
    "merged = Fresh_Leads_format.merge(\n",
    "    acra_data_mapped[[\n",
    "        \"UEN\",\n",
    "        \"ENTITY_NAME\",\n",
    "        \"PRIMARY_SSIC_CODE\",\n",
    "        \"SECONDARY_SSIC_CODE\",\n",
    "        \"REGISTRATION_INCORPORATION_DATE\",\n",
    "        \"ENTITY_TYPE_DESCRIPTION\",\n",
    "        \"BUSINESS_TYPE\",\n",
    "        \"PARENT_INDUSTRY\",\n",
    "        \"INDUSTRY_TYPE\",\n",
    "        \"SUB_INDUSTRY\",\n",
    "        \"BLOCK\",\n",
    "        \"STREET_NAME\",\n",
    "        \"UNIT_NO\",\n",
    "        \"POSTAL_CODE\"\n",
    "    ]],\n",
    "    left_on=\"Company Registration Number (UEN)\",\n",
    "    right_on=\"UEN\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Create combined address fields\n",
    "merged['REGISTERED_ADDRESS_COMBINED'] = (\n",
    "    merged['BLOCK'].fillna('').astype(str) + ' ' + \n",
    "    merged['STREET_NAME'].fillna('').astype(str)\n",
    ").str.strip().replace('', np.nan)\n",
    "\n",
    "# Map ACRA data to Fresh_Leads_format columns\n",
    "merged[\"ACRA REGISTERED NAME\"] = merged[\"ENTITY_NAME\"]\n",
    "merged[\"Brand/Deal Name/Business Name\"] = merged[\"ENTITY_NAME\"]\n",
    "merged[\"Primary SSIC Code\"] = merged[\"PRIMARY_SSIC_CODE\"]\n",
    "merged[\"Secondary SSIC Code\"] = merged[\"SECONDARY_SSIC_CODE\"]\n",
    "merged[\"Company Registration date / Date Established\"] = merged[\"REGISTRATION_INCORPORATION_DATE\"]\n",
    "merged[\"Ownership Type\"] = merged[\"ENTITY_TYPE_DESCRIPTION\"]\n",
    "merged[\"Business Type\"] = merged[\"BUSINESS_TYPE\"]\n",
    "merged[\"Parent Industry Type\"] = merged[\"PARENT_INDUSTRY\"]\n",
    "merged[\"Industry Type\"] = merged[\"INDUSTRY_TYPE\"]\n",
    "merged[\"Sub Industry\"] = merged[\"SUB_INDUSTRY\"]\n",
    "merged[\"Registered Address (Block & Street)\"] = merged['REGISTERED_ADDRESS_COMBINED']\n",
    "merged[\"Registered Address  (Unit #)\"] = merged[\"UNIT_NO\"]\n",
    "merged[\"Registered Address  (Postal code)\"] = merged[\"POSTAL_CODE\"]\n",
    "merged[\"Operational Address \\n(Unit #)\"] = merged[\"UNIT_NO\"]\n",
    "merged[\"Operational Address \\n(Postal Code)\"] = merged[\"POSTAL_CODE\"]\n",
    "\n",
    "# Keep ONLY the original Fresh_Leads_format columns and make a proper copy\n",
    "Fresh_Leads_formatted = merged[Fresh_Leads_format.columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0432a1f",
   "metadata": {},
   "source": [
    "### EPOS Backend Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c7ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epos_backend_df = pd.read_csv(\n",
    "    \"./Epos_Backend/organizations_export.csv\",\n",
    "    on_bad_lines=\"skip\"  # skips rows with too many or too few fields\n",
    ")\n",
    "\n",
    "epos_backend_df = epos_backend_df.loc[\n",
    "    epos_backend_df[\"status\"] == \"Active\",\n",
    "    [\"organization_name\", \"status\"]\n",
    "]\n",
    "\n",
    "epos_backend_df\n",
    "\n",
    "# Initialize \"Current ePOS Client ?\" column with \"No\" for all rows\n",
    "Fresh_Leads_formatted['Current ePOS Client ?'] = 'No'\n",
    "\n",
    "# Clean and prepare the data for matching\n",
    "# Convert to string and strip, but keep all rows (including NaN)\n",
    "Fresh_Leads_formatted['ACRA REGISTERED NAME_cleaned'] = Fresh_Leads_formatted['ACRA REGISTERED NAME'].astype(str).str.strip()\n",
    "epos_backend_names = epos_backend_df['organization_name'].dropna().astype(str).str.strip().tolist()\n",
    "\n",
    "# Set similarity threshold (100% match - exact match only)\n",
    "THRESHOLD = 100\n",
    "\n",
    "# Track matches\n",
    "matches_found = []\n",
    "matched_indices = []\n",
    "\n",
    "# Get rows with valid (non-null, non-nan) names\n",
    "valid_name_mask = (\n",
    "    Fresh_Leads_formatted['ACRA REGISTERED NAME'].notna() & \n",
    "    (Fresh_Leads_formatted['ACRA REGISTERED NAME_cleaned'] != 'nan') &\n",
    "    (Fresh_Leads_formatted['ACRA REGISTERED NAME_cleaned'] != '')\n",
    ")\n",
    "\n",
    "valid_rows = Fresh_Leads_formatted[valid_name_mask]\n",
    "print(f\"Checking {len(valid_rows)} names against {len(epos_backend_names)} ePOS backend organizations...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# For each row with a valid name, check if it exists in ePOS backend\n",
    "for idx, row in valid_rows.iterrows():\n",
    "    name = row['ACRA REGISTERED NAME_cleaned']\n",
    "    \n",
    "    # Find the best match using fuzzy matching\n",
    "    best_match = process.extractOne(\n",
    "        name, \n",
    "        epos_backend_names,\n",
    "        scorer=fuzz.token_sort_ratio\n",
    "    )\n",
    "    \n",
    "    if best_match and best_match[1] >= THRESHOLD:\n",
    "        matches_found.append({\n",
    "            'Fresh Lead Name': name,\n",
    "            'Matched ePOS Name': best_match[0],\n",
    "            'Similarity Score': best_match[1]\n",
    "        })\n",
    "        matched_indices.append(idx)  # Store the original index\n",
    "        # Update the dataframe: set \"Current ePOS Client ?\" to \"Yes\" for this row\n",
    "        Fresh_Leads_formatted.at[idx, 'Current ePOS Client ?'] = 'Yes'\n",
    "        print(f\"yes there's exist!\")\n",
    "        print(f\"  Fresh Lead: {name}\")\n",
    "        print(f\"  Matched with: {best_match[0]}\")\n",
    "        print(f\"  Similarity: {best_match[1]}%\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Create Epos_Client_df from matched rows (those with 100% similarity)\n",
    "Epos_Client_df = Fresh_Leads_formatted.loc[matched_indices].copy()\n",
    "\n",
    "# Drop matched rows from Fresh_Leads_formatted\n",
    "Fresh_Leads_formatted = Fresh_Leads_formatted.drop(index=matched_indices)\n",
    "\n",
    "# Drop the temporary cleaned column from both dataframes\n",
    "Fresh_Leads_formatted = Fresh_Leads_formatted.drop(columns=['ACRA REGISTERED NAME_cleaned'])\n",
    "Epos_Client_df = Epos_Client_df.drop(columns=['ACRA REGISTERED NAME_cleaned'])\n",
    "\n",
    "# Reset indices\n",
    "Fresh_Leads_formatted = Fresh_Leads_formatted.reset_index(drop=True)\n",
    "Epos_Client_df = Epos_Client_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n\\nTotal matches found: {len(matches_found)} out of {len(valid_rows)}\")\n",
    "print(f\"Rows transferred to Epos_Client_df: {len(Epos_Client_df)}\")\n",
    "print(f\"Rows remaining in Fresh_Leads_formatted: {len(Fresh_Leads_formatted)}\")\n",
    "\n",
    "# Create a summary DataFrame\n",
    "if matches_found:\n",
    "    matches_df = pd.DataFrame(matches_found)\n",
    "    print(\"\\nSummary of matches:\")\n",
    "    print(matches_df)\n",
    "else:\n",
    "    print(\"\\nNo matches found above the threshold.\")\n",
    "\n",
    "# Display both dataframes\n",
    "print(\"\\n\\nEpos_Client_df (existing clients with 100% match):\")\n",
    "print(Epos_Client_df[['ACRA REGISTERED NAME', 'Current ePOS Client ?']].head(20))\n",
    "\n",
    "print(\"\\n\\nFresh_Leads_formatted (remaining leads):\")\n",
    "print(Fresh_Leads_formatted[['ACRA REGISTERED NAME', 'Current ePOS Client ?']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epos_Client_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf9656",
   "metadata": {},
   "source": [
    "### Prefil Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a1528",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads_formatted['Date'] = pd.Timestamp.today().normalize()\n",
    "Fresh_Leads_formatted['Date'] = Fresh_Leads_formatted['Date'].dt.strftime(\"%d,%m,%Y\")\n",
    "\n",
    "# fill specific columns with given values\n",
    "Fresh_Leads_formatted[\"Tele Sales or MR (For KPI - Internal)\"] = \"TeleSales\"\n",
    "Fresh_Leads_formatted[\"Name of the Market Researcher\"] = \"Hazim\"\n",
    "Fresh_Leads_formatted[\"Original Source (Marketing)\"] = \"Offline Sources\"\n",
    "Fresh_Leads_formatted[\"Marketing Source (Do not fill anything if the leads are from Hubspot, EPOS clients)\"] = \"Web Scrapping\"\n",
    "Fresh_Leads_formatted[\"Is this deal part of the Gov List?\"] = \"Gov List\"\n",
    "Fresh_Leads_formatted[\"Contact Number from Lusha?\"] = \"No\"\n",
    "Fresh_Leads_formatted[\"Source from Market Researcher\"] = [[\"ACRA\", \"Google Searches\"]] * len(Fresh_Leads_formatted)\n",
    "Fresh_Leads_formatted[\"Business model\"] = [[\"B2C\", \"Offline\"]] * len(Fresh_Leads_formatted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d151e467",
   "metadata": {},
   "source": [
    "### Cleaning & Reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e045129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE DATA CLEANING MODULE\n",
    "# ============================================================================\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1. COMPANY NAME CLEANING\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def clean_company_name(name):\n",
    "    \"\"\"\n",
    "    Remove common company suffixes and clean company names.\n",
    "    Handles Singapore, Malaysia, and international suffixes.\n",
    "    \"\"\"\n",
    "    # Handle list/array values\n",
    "    if isinstance(name, (list, np.ndarray)):\n",
    "        if len(name) == 0:\n",
    "            return pd.NA\n",
    "        name = ', '.join([str(n) for n in name if n is not None and str(n).strip() not in ['', 'nan', 'None', 'null']])\n",
    "        if not name:\n",
    "            return pd.NA\n",
    "    \n",
    "    if name is None:\n",
    "        return pd.NA\n",
    "    \n",
    "    try:\n",
    "        if pd.isna(name):\n",
    "            return pd.NA\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    \n",
    "    if str(name).strip() == '':\n",
    "        return pd.NA\n",
    "    \n",
    "    name = str(name).strip()\n",
    "    \n",
    "    # Remove common company suffixes (expanded list)\n",
    "    name = re.sub(\n",
    "        r'\\b(PTE\\.?\\s*LTD\\.?|PTE\\.?|LTD\\.?|LIMITED|SDN\\.?\\s*BHD\\.?|SDN\\.?|BHD\\.?|'\n",
    "        r'INC\\.?|INCORPORATED|CORP\\.?|CORPORATION|LLP|LLC|PLC|'\n",
    "        r'CO\\.?|COMPANY|COMPANIES|ENTERPRISE|ENTERPRISES|TRADING|'\n",
    "        r'PLT|SINGAPORE|SG|HOLDINGS?|HOLDING|GROUP|'\n",
    "        r'PRIVATE|PUBLIC|INTERNATIONAL|INTL\\.?|GLOBAL|'\n",
    "        r'SERVICES?|SOLUTIONS?|SYSTEMS?|TECHNOLOGIES|TECH)\\b',\n",
    "        '', name, flags=re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Remove extra punctuation but keep meaningful characters (hyphen at end to avoid range error)\n",
    "    name = re.sub(r'[^\\w\\s&@#+\\-]', '', name)  # Keep alphanumeric, &, @, #, +, -, spaces\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    \n",
    "    # Remove trailing/leading special characters (hyphen at end)\n",
    "    name = re.sub(r'^[&@#+\\-\\s]+|[&@#+\\-\\s]+$', '', name).strip()\n",
    "    \n",
    "    return name if name else pd.NA\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2. PHONE NUMBER CLEANING & FORMATTING\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def _clean_single_phone(phone):\n",
    "    \"\"\"Clean a single phone number.\"\"\"\n",
    "    if phone is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if pd.isna(phone):\n",
    "            return None\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    \n",
    "    if str(phone).strip() in ['', 'nan', 'None', 'null']:\n",
    "        return None\n",
    "    \n",
    "    # Convert to string and extract all digits\n",
    "    digits = re.sub(r'\\D', '', str(phone))\n",
    "    \n",
    "    if not digits:\n",
    "        return None\n",
    "    \n",
    "    # Remove leading zeros\n",
    "    digits = digits.lstrip('0')\n",
    "    \n",
    "    # Handle country codes\n",
    "    if digits.startswith('65'):\n",
    "        # Singapore number with country code\n",
    "        local_part = digits[2:]\n",
    "        if len(local_part) >= 8:\n",
    "            return f\"65 {local_part[:4]} {local_part[4:8]}\"\n",
    "        elif len(local_part) >= 4:\n",
    "            return f\"65 {local_part}\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    elif len(digits) == 8:\n",
    "        # Local Singapore number without country code\n",
    "        return f\"65 {digits[:4]} {digits[4:]}\"\n",
    "    \n",
    "    elif len(digits) == 10 and digits.startswith('65'):\n",
    "        # 65XXXXXXXX format\n",
    "        return f\"65 {digits[2:6]} {digits[6:10]}\"\n",
    "    \n",
    "    elif len(digits) > 8:\n",
    "        # Assume first part is country code, take last 8 digits as local number\n",
    "        local_part = digits[-8:]\n",
    "        return f\"65 {local_part[:4]} {local_part[4:]}\"\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_phone_number(phone):\n",
    "    \"\"\"\n",
    "    Clean and format phone numbers to Singapore standard: 65 XXXX XXXX\n",
    "    Handles various input formats including lists/arrays.\n",
    "    \"\"\"\n",
    "    # Handle list/array values - process each and join\n",
    "    if isinstance(phone, (list, np.ndarray)):\n",
    "        if len(phone) == 0:\n",
    "            return pd.NA\n",
    "        # Clean each phone number in the list\n",
    "        cleaned_phones = []\n",
    "        for p in phone:\n",
    "            cleaned = _clean_single_phone(p)\n",
    "            if cleaned:\n",
    "                cleaned_phones.append(cleaned)\n",
    "        if cleaned_phones:\n",
    "            # Remove duplicates while preserving order\n",
    "            seen = set()\n",
    "            unique_phones = []\n",
    "            for p in cleaned_phones:\n",
    "                if p not in seen:\n",
    "                    seen.add(p)\n",
    "                    unique_phones.append(p)\n",
    "            return ', '.join(unique_phones)\n",
    "        return pd.NA\n",
    "    \n",
    "    result = _clean_single_phone(phone)\n",
    "    return result if result else pd.NA\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3. EMAIL CLEANING\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def _clean_single_email(email):\n",
    "    \"\"\"Clean a single email address.\"\"\"\n",
    "    if email is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if pd.isna(email):\n",
    "            return None\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    \n",
    "    if str(email).strip() in ['', 'nan', 'None', 'null']:\n",
    "        return None\n",
    "    \n",
    "    email = str(email).strip()\n",
    "    \n",
    "    # Remove brackets, quotes, and other unwanted characters\n",
    "    email = re.sub(r'[\\[\\]\\'\\\"+,]', '', email)\n",
    "    email = email.strip().lower()\n",
    "    \n",
    "    # Basic email validation\n",
    "    if re.match(r'^[a-z0-9][a-z0-9._-]*@[a-z0-9][a-z0-9.-]+\\.[a-z]{2,}$', email):\n",
    "        return email\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_email(email):\n",
    "    \"\"\"\n",
    "    Clean and validate email addresses.\n",
    "    Handles lists/arrays of emails.\n",
    "    \"\"\"\n",
    "    # Handle list/array values\n",
    "    if isinstance(email, (list, np.ndarray)):\n",
    "        if len(email) == 0:\n",
    "            return pd.NA\n",
    "        cleaned_emails = []\n",
    "        for e in email:\n",
    "            cleaned = _clean_single_email(e)\n",
    "            if cleaned:\n",
    "                cleaned_emails.append(cleaned)\n",
    "        if cleaned_emails:\n",
    "            # Remove duplicates while preserving order\n",
    "            seen = set()\n",
    "            unique_emails = []\n",
    "            for e in cleaned_emails:\n",
    "                if e not in seen:\n",
    "                    seen.add(e)\n",
    "                    unique_emails.append(e)\n",
    "            return ', '.join(unique_emails)\n",
    "        return pd.NA\n",
    "    \n",
    "    result = _clean_single_email(email)\n",
    "    return result if result else pd.NA\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4. URL CLEANING (for social media and websites)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def _clean_single_url(url):\n",
    "    \"\"\"Clean a single URL.\"\"\"\n",
    "    if url is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if pd.isna(url):\n",
    "            return None\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    \n",
    "    if str(url).strip() in ['', 'nan', 'None', 'null']:\n",
    "        return None\n",
    "    \n",
    "    url = str(url).strip()\n",
    "    \n",
    "    # Remove brackets, quotes, commas\n",
    "    url = re.sub(r'[\\[\\]\\'\\\"+,]', '', url)\n",
    "    url = url.strip()\n",
    "    \n",
    "    # Basic URL validation (starts with http/https or www or common domains)\n",
    "    if re.match(r'^(https?://|www\\.|[a-z]+\\.(com|sg|net|org|co))', url, re.IGNORECASE):\n",
    "        return url\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_url(url):\n",
    "    \"\"\"\n",
    "    Clean URLs by removing brackets, quotes, and validating format.\n",
    "    Handles lists/arrays of URLs.\n",
    "    \"\"\"\n",
    "    # Handle list/array values\n",
    "    if isinstance(url, (list, np.ndarray)):\n",
    "        if len(url) == 0:\n",
    "            return pd.NA\n",
    "        cleaned_urls = []\n",
    "        for u in url:\n",
    "            cleaned = _clean_single_url(u)\n",
    "            if cleaned:\n",
    "                cleaned_urls.append(cleaned)\n",
    "        if cleaned_urls:\n",
    "            # Remove duplicates while preserving order\n",
    "            seen = set()\n",
    "            unique_urls = []\n",
    "            for u in cleaned_urls:\n",
    "                if u not in seen:\n",
    "                    seen.add(u)\n",
    "                    unique_urls.append(u)\n",
    "            return ', '.join(unique_urls)\n",
    "        return pd.NA\n",
    "    \n",
    "    result = _clean_single_url(url)\n",
    "    return result if result else pd.NA\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5. LIST/ARRAY COLUMN CLEANING\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def clean_list_column(value):\n",
    "    \"\"\"\n",
    "    Clean columns that contain list/array values.\n",
    "    Handles both actual Python lists and stringified lists.\n",
    "    Returns as comma-separated string.\n",
    "    \"\"\"\n",
    "    # Handle actual None/NaN values\n",
    "    if value is None:\n",
    "        return pd.NA\n",
    "    \n",
    "    # Check if it's already a pandas NA\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return pd.NA\n",
    "    except (ValueError, TypeError):\n",
    "        # If pd.isna() fails (for lists), continue processing\n",
    "        pass\n",
    "    \n",
    "    # If it's already a list or numpy array, convert to comma-separated string\n",
    "    if isinstance(value, (list, np.ndarray)):\n",
    "        if len(value) == 0:\n",
    "            return pd.NA\n",
    "        # Clean each item in the list\n",
    "        cleaned_items = [str(item).strip() for item in value if item is not None and str(item).strip() not in ['', 'nan', 'None', 'null']]\n",
    "        if cleaned_items:\n",
    "            return ', '.join(cleaned_items)\n",
    "        else:\n",
    "            return pd.NA\n",
    "    \n",
    "    # Convert to string for string-based processing\n",
    "    value_str = str(value).strip()\n",
    "    \n",
    "    # Check for empty or null strings\n",
    "    if value_str in ['', 'nan', 'None', 'null']:\n",
    "        return pd.NA\n",
    "    \n",
    "    # Remove brackets and quotes from stringified lists\n",
    "    value_str = re.sub(r'[\\[\\]\\'\\\"+]', '', value_str)\n",
    "    \n",
    "    # Clean up commas and spaces\n",
    "    value_str = re.sub(r'\\s*,\\s*', ', ', value_str).strip()\n",
    "    \n",
    "    return value_str if value_str else pd.NA\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6. TEXT COLUMN CLEANING\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def clean_text_column(value):\n",
    "    \"\"\"\n",
    "    Clean general text columns.\n",
    "    Handles lists/arrays by joining them.\n",
    "    \"\"\"\n",
    "    # Handle list/array values\n",
    "    if isinstance(value, (list, np.ndarray)):\n",
    "        if len(value) == 0:\n",
    "            return pd.NA\n",
    "        cleaned_items = [str(item).strip() for item in value if item is not None and str(item).strip() not in ['', 'nan', 'None', 'null']]\n",
    "        if cleaned_items:\n",
    "            return ', '.join(cleaned_items)\n",
    "        return pd.NA\n",
    "    \n",
    "    if value is None:\n",
    "        return pd.NA\n",
    "    \n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return pd.NA\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    \n",
    "    value_str = str(value).strip()\n",
    "    if value_str in ['', 'nan', 'None', 'null']:\n",
    "        return pd.NA\n",
    "    \n",
    "    return value_str\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 7. APPLY CLEANING TO ALL COLUMNS (SILENT MODE)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# Clean Company/Brand Names (ONLY Brand/Deal Name, NOT ACRA REGISTERED NAME)\n",
    "if \"Brand/Deal Name/Business Name\" in Fresh_Leads_formatted.columns:\n",
    "    Fresh_Leads_formatted[\"Brand/Deal Name/Business Name\"] = Fresh_Leads_formatted[\"Brand/Deal Name/Business Name\"].apply(clean_company_name)\n",
    "\n",
    "# Clean Phone Numbers\n",
    "phone_columns = [\"PIC NAME 1 Contact Number\", \"PIC NAME 2 Contact Number\", \"PIC NAME 3 Contact Number\", \"Contact Number from Lusha?\"]\n",
    "for col in phone_columns:\n",
    "    if col in Fresh_Leads_formatted.columns:\n",
    "        Fresh_Leads_formatted[col] = Fresh_Leads_formatted[col].apply(clean_phone_number)\n",
    "\n",
    "# Clean Emails\n",
    "email_columns = [\"PIC 1 email address\", \"PIC 2 email address\", \"PIC 3 email address\"]\n",
    "for col in email_columns:\n",
    "    if col in Fresh_Leads_formatted.columns:\n",
    "        Fresh_Leads_formatted[col] = Fresh_Leads_formatted[col].apply(clean_email)\n",
    "\n",
    "# Clean URLs (Social Media & Websites)\n",
    "url_columns = [\"Website URL\", \"Facebook Page\", \"Instagram URL\", \"Linkedin URL\", \"Tik Tok URL\", \n",
    "               \"Sub Domain Link (If Lead is already available in Backend) Fill only when EPOS client\"]\n",
    "for col in url_columns:\n",
    "    if col in Fresh_Leads_formatted.columns:\n",
    "        Fresh_Leads_formatted[col] = Fresh_Leads_formatted[col].apply(clean_url)\n",
    "\n",
    "# Clean List/Array Columns\n",
    "list_columns = [\"Source from Market Researcher\", \"Business model\", \"FB/Insta/Tik Tok/Linkedin Contact\"]\n",
    "for col in list_columns:\n",
    "    if col in Fresh_Leads_formatted.columns:\n",
    "        Fresh_Leads_formatted[col] = Fresh_Leads_formatted[col].apply(clean_list_column)\n",
    "\n",
    "# Clean Text Columns (General)\n",
    "text_columns = [\"First Name\", \"Last Name\", \"First Name 2\", \"Last Name 2\", \"First Name 3\", \"Last Name 3\",\n",
    "                \"PIC Name 1 Designation\", \"PIC Name 2 Designation\", \"PIC Name Designation 3\",\n",
    "                \"Name of the Market Researcher\", \"Tele Sales or MR (For KPI - Internal)\"]\n",
    "for col in text_columns:\n",
    "    if col in Fresh_Leads_formatted.columns:\n",
    "        Fresh_Leads_formatted[col] = Fresh_Leads_formatted[col].apply(clean_text_column)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 8. CORE INDICATORS - CLEANING STATUS & DUPLICATES\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for duplicate UENs\n",
    "uen_has_duplicates = False\n",
    "if \"Company Registration Number (UEN)\" in Fresh_Leads_formatted.columns:\n",
    "    uen_duplicates = Fresh_Leads_formatted[Fresh_Leads_formatted.duplicated(subset=[\"Company Registration Number (UEN)\"], keep=False)]\n",
    "    uen_dup_count = len(uen_duplicates)\n",
    "    if uen_dup_count > 0:\n",
    "        uen_has_duplicates = True\n",
    "        print(f\"[!] UEN Duplicates: {uen_dup_count} rows ({uen_duplicates['Company Registration Number (UEN)'].nunique()} unique UENs)\")\n",
    "    else:\n",
    "        print(f\"[OK] UEN Duplicates: None\")\n",
    "\n",
    "# Check for duplicate Phone Numbers\n",
    "phone_has_duplicates = False\n",
    "if \"PIC NAME 1 Contact Number\" in Fresh_Leads_formatted.columns:\n",
    "    phone_duplicates = Fresh_Leads_formatted[\n",
    "        Fresh_Leads_formatted.duplicated(subset=[\"PIC NAME 1 Contact Number\"], keep=False) &\n",
    "        Fresh_Leads_formatted[\"PIC NAME 1 Contact Number\"].notna()\n",
    "    ]\n",
    "    phone_dup_count = len(phone_duplicates)\n",
    "    if phone_dup_count > 0:\n",
    "        phone_has_duplicates = True\n",
    "        print(f\"[!] Phone Duplicates: {phone_dup_count} rows ({phone_duplicates['PIC NAME 1 Contact Number'].nunique()} unique numbers)\")\n",
    "    else:\n",
    "        print(f\"[OK] Phone Duplicates: None\")\n",
    "\n",
    "# Cleaning completion status\n",
    "print(f\"\\n[OK] All columns cleaned successfully\")\n",
    "print(f\"     (Excluded: ACRA REGISTERED NAME, UEN)\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads_formatted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7632c6fa",
   "metadata": {},
   "source": [
    "### Examine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0406caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Fresh_Leads_formatted.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd88686",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads_formatted[\"PIC 1 Source\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check uniqueness for both columns\n",
    "uen_unique = Fresh_Leads_formatted[\"Company Registration Number (UEN)\"].is_unique\n",
    "phone_unique = Fresh_Leads_formatted[\"PIC NAME 1 Contact Number\"].is_unique\n",
    "\n",
    "print(f\"Company Registration Number (UEN) all unique: {uen_unique}\")\n",
    "print(f\"PIC NAME 1 Contact Number all unique: {phone_unique}\")\n",
    "\n",
    "# If not unique, show duplicate counts\n",
    "if not uen_unique:\n",
    "    uen_dups = Fresh_Leads_formatted[\"Company Registration Number (UEN)\"].duplicated(keep=False).sum()\n",
    "    print(f\"  -> UEN duplicates: {uen_dups} rows\")\n",
    "\n",
    "if not phone_unique:\n",
    "    # Exclude NaN from duplicate check for phone\n",
    "    phone_non_null = Fresh_Leads_formatted[Fresh_Leads_formatted[\"PIC NAME 1 Contact Number\"].notna()]\n",
    "    phone_dups = phone_non_null[\"PIC NAME 1 Contact Number\"].duplicated(keep=False).sum()\n",
    "    print(f\"  -> Phone duplicates (excluding NaN): {phone_dups} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Fresh_Leads_formatted[[\n",
    "    \"ACRA REGISTERED NAME\",\n",
    "    \"Brand/Deal Name/Business Name\",\n",
    "    \"PIC NAME 1 Contact Number\",\n",
    "    \"Business Type\",\n",
    "    \"Registered Address (Block & Street)\", \n",
    "    \"Registered Address (Unit #)\", \n",
    "    \"Registered Address (Postal code)\", \n",
    "    \"Operational Address \\n(Postal Code)\",\n",
    "    \"PIC 1 Source\"\n",
    "]]\n",
    "x.tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads_formatted.to_parquet(\"./Staging/Gold/Gold_Data_Hawker_2.parquet\", index=False, engine=\"fastparquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
