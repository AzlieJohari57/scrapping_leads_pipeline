{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6ed9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "import asyncio\n",
    "\n",
    "# Third-party HTTP / async\n",
    "import requests\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "\n",
    "# Data & analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Web scraping\n",
    "import scrapy\n",
    "from scrapy_playwright.page import PageMethod\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Fuzzy matching\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Apify\n",
    "from apify_client import ApifyClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229090a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STB TRAVEL AGENT SCRAPER - COST OPTIMIZED\n",
      "============================================================\n",
      "Configuration:\n",
      "  - Start page: 0\n",
      "  - Total pages: 100\n",
      "  - Batch size: 50\n",
      "  - Concurrency: 3\n",
      "  - Total batches: 2\n",
      "  - Memory: 2048 MB (optimized)\n",
      "  - Proxy: Default Apify proxy\n",
      "\n",
      "==================================================\n",
      "BATCH 1: Pages 0 to 49\n",
      "==================================================\n",
      "\n",
      "[Batch 1] Starting 50 pages with concurrency=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:31:46.538Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:31:46.540Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:31:46.579Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:31:46.791Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:31:47.551Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:31:47.707Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:31:48.406Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 2/50 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 6/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 9/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 14/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 18/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:31:48.507Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:32:48.514Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":6427,\"requestsFinishedPerMinute\":21,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":134959,\"requestsTotal\":21,\"crawlerRuntimeMillis\":60171,\"retryHistogram\":[21]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 21/50 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 25/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 29/50 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 32/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 35/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 40/50 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:32:48.537Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":2,\"desiredConcurrency\":1,\"systemStatus\":{\"isSystemIdle\":false,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0.02},\"cpuInfo\":{\"isOverloaded\":true,\"limitRatio\":0.4,\"actualRatio\":0.408},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:33:48.514Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":5667,\"requestsFinishedPerMinute\":22,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":249362,\"requestsTotal\":44,\"crawlerRuntimeMillis\":120172,\"retryHistogram\":[44]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 44/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: RUNNING, Message: Crawled 47/50 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:33:48.614Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":2,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0.363},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:34:04.695Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:34:05.058Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":50,\"requestsFailed\":0,\"retryHistogram\":[50],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":5620,\"requestsFinishedPerMinute\":22,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":280993,\"requestsTotal\":50,\"crawlerRuntimeMillis\":136715}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:34:05.058Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 50 requests: 50 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> 2026-01-26T03:34:05.074Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uppqKzMLHTbSbs1eS]\u001b[0m -> Status: SUCCEEDED, Message: Finished! Total 50 requests: 50 succeeded, 0 failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1] Actor status: SUCCEEDED\n",
      "[Batch 1] Extracted 750 agents\n",
      "Running total: 750 agents\n",
      "\n",
      "==================================================\n",
      "BATCH 2: Pages 50 to 99\n",
      "==================================================\n",
      "\n",
      "[Batch 2] Starting 50 pages with concurrency=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:34:13.025Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:34:13.027Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:34:13.068Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:34:13.399Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:34:14.372Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:34:14.523Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:34:15.142Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 2/50 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 4/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 8/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:34:15.223Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:35:15.223Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":9133,\"requestsFinishedPerMinute\":12,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":109598,\"requestsTotal\":12,\"crawlerRuntimeMillis\":60156,\"retryHistogram\":[12]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 12/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 15/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 18/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 21/50 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 23/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:35:15.300Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":3,\"desiredConcurrency\":3,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0.122},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:36:15.223Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":8682,\"requestsFinishedPerMinute\":12,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":208377,\"requestsTotal\":24,\"crawlerRuntimeMillis\":120157,\"retryHistogram\":[24]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 24/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 25/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 26/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:36:15.301Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":3,\"desiredConcurrency\":3,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0.019},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 28/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 30/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:36:39.773Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. requestHandler timed out after 60 seconds.\u001b[90m {\"id\":\"XHDKmaoUUeMZylV\",\"url\":\"https://trust.stb.gov.sg/site/content/tagaem/landing-page/travel-agent.html?service=ALL&type=ALL&status=TA_A&curIndex=85\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:37:15.223Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":10501,\"requestsFinishedPerMinute\":10,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":315021,\"requestsTotal\":30,\"crawlerRuntimeMillis\":180157,\"retryHistogram\":[30]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 31/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:37:15.334Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":3,\"desiredConcurrency\":3,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0.071},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 34/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 36/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:37:45.022Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. requestHandler timed out after 60 seconds.\u001b[90m {\"id\":\"ZWuqsl7z3aoqj9T\",\"url\":\"https://trust.stb.gov.sg/site/content/tagaem/landing-page/travel-agent.html?service=ALL&type=ALL&status=TA_A&curIndex=66\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:38:15.223Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":12285,\"requestsFinishedPerMinute\":9,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":454562,\"requestsTotal\":37,\"crawlerRuntimeMillis\":240156,\"retryHistogram\":[37]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 37/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 41/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 42/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 44/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:38:15.312Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":3,\"desiredConcurrency\":3,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:39:15.224Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":12824,\"requestsFinishedPerMinute\":9,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":564239,\"requestsTotal\":44,\"crawlerRuntimeMillis\":300157,\"retryHistogram\":[44]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:39:15.313Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":3,\"desiredConcurrency\":3,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:39:19.209Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. requestHandler timed out after 60 seconds.\u001b[90m {\"id\":\"uuMgDhJbsQ3Ub6V\",\"url\":\"https://trust.stb.gov.sg/site/content/tagaem/landing-page/travel-agent.html?service=ALL&type=ALL&status=TA_A&curIndex=95\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 45/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 46/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 47/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 48/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> 2026-01-26T03:39:26.133Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. requestHandler timed out after 60 seconds.\u001b[90m {\"id\":\"9WYk6AfHx4vRYI7\",\"url\":\"https://trust.stb.gov.sg/site/content/tagaem/landing-page/travel-agent.html?service=ALL&type=ALL&status=TA_A&curIndex=96\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: RUNNING, Message: Crawled 49/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:vkddUEUXQEfFUxnvv]\u001b[0m -> Status: SUCCEEDED, Message: Finished! Total 50 requests: 50 succeeded, 0 failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2] Actor status: SUCCEEDED\n",
      "  Page 50 failed: Waiting for selector `.name` failed\n",
      "  Page 84 failed: Waiting for selector `.name` failed\n",
      "  Page 86 failed: Waiting for selector `.name` failed\n",
      "  Page 87 failed: Waiting for selector `.name` failed\n",
      "  Page 88 failed: Waiting for selector `.name` failed\n",
      "  Page 89 failed: Waiting for selector `.name` failed\n",
      "  Page 90 failed: Waiting for selector `.name` failed\n",
      "  Page 91 failed: Waiting for selector `.name` failed\n",
      "  Page 92 failed: Waiting for selector `.name` failed\n",
      "  Page 93 failed: Waiting for selector `.name` failed\n",
      "  Page 94 failed: Waiting for selector `.name` failed\n",
      "  Page 97 failed: Waiting for selector `.name` failed\n",
      "  Page 96 failed: Waiting for selector `.name` failed\n",
      "  Page 98 failed: Waiting for selector `.name` failed\n",
      "  Page 99 failed: Waiting for selector `.name` failed\n",
      "  Page 85 failed: Waiting for selector `.name` failed\n",
      "  Page 95 failed: Waiting for selector `.name` failed\n",
      "  Page 96 failed: Waiting for selector `.name` failed\n",
      "[Batch 2] Extracted 487 agents\n",
      "Running total: 1237 agents\n",
      "\n",
      "============================================================\n",
      "SCRAPE COMPLETE\n",
      "============================================================\n",
      "Total agents extracted: 1237\n",
      "Failed pages: 18\n",
      "Duration: 0:08:47.170922\n",
      "Failed page indices: [50, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 96, 98, 99, 85, 95, 96]\n",
      "Unique agents (after dedup): 1237\n"
     ]
    }
   ],
   "source": [
    "# STB TRAVEL AGENT SCRAPER - COST OPTIMIZED\n",
    "from apify_client import ApifyClient\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "client = ApifyClient(\"\")\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION (COST OPTIMIZED)\n",
    "# ============================================================\n",
    "MAX_CONCURRENCY = 3          # Reduced for stability and lower memory\n",
    "MAX_RETRIES = 2              # Retries per failed page\n",
    "BATCH_SIZE = 50              # Increased - fewer actor runs = less startup overhead\n",
    "TOTAL_PAGES = 100             # Total pages to scrape (adjust based on site)\n",
    "START_PAGE = 0               # Starting page index\n",
    "\n",
    "def create_stb_pagefunction_optimized() -> str:\n",
    "    \"\"\"OPTIMIZED: Removed fixed delays, uses fallback selectors\"\"\"\n",
    "    return \"\"\"\n",
    "async function pageFunction(context) {\n",
    "    const { page, log, request } = context;\n",
    "    const pageIndex = request?.userData?.pageIndex ?? 0;\n",
    "    \n",
    "    try {\n",
    "        // Wait for cards with fallback selectors (no fixed delays)\n",
    "        try {\n",
    "            await page.waitForSelector('.box-list.grid', { timeout: 20000 });\n",
    "        } catch (e) {\n",
    "            // Fallback: try waiting for individual card elements\n",
    "            await page.waitForSelector('.name', { timeout: 10000 });\n",
    "        }\n",
    "        \n",
    "        // Extract all travel agents\n",
    "        const agents = await page.evaluate(() => {\n",
    "            const results = [];\n",
    "            \n",
    "            // Select all company cards\n",
    "            const cards = document.querySelectorAll('.box-list.grid');\n",
    "            \n",
    "            cards.forEach((card) => {\n",
    "                try {\n",
    "                    // Company Name - clean text only\n",
    "                    const nameEl = card.querySelector('.name');\n",
    "                    const companyName = nameEl ? nameEl.textContent.trim() : null;\n",
    "                    \n",
    "                    // Address\n",
    "                    const addressEl = card.querySelector('.address');\n",
    "                    const address = addressEl ? addressEl.textContent.trim() : null;\n",
    "                    \n",
    "                    // License ID\n",
    "                    const licenseEl = card.querySelector('.license');\n",
    "                    const licenseId = licenseEl ? licenseEl.textContent.trim() : null;\n",
    "                    \n",
    "                    // License Type\n",
    "                    const typeEl = card.querySelector('.license_type');\n",
    "                    const licenseType = typeEl ? typeEl.textContent.trim() : null;\n",
    "                    \n",
    "                    // Phone - from tel: link (FIXED: decode URL-encoded characters like %20)\n",
    "                    let phone = null;\n",
    "                    const phoneLink = card.querySelector('a[href^=\"tel:\"]');\n",
    "                    if (phoneLink) {\n",
    "                        // Decode URL encoding (%20 -> space) then extract digits\n",
    "                        const rawPhone = decodeURIComponent(phoneLink.href.replace('tel:', '')).trim();\n",
    "                        const digits = rawPhone.replace(/\\\\D/g, '');\n",
    "                        if (digits.length === 8) {\n",
    "                            phone = '+65' + digits;\n",
    "                        } else {\n",
    "                            phone = '+65' + digits;\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    // Email - from mailto: link\n",
    "                    let email = null;\n",
    "                    const emailLink = card.querySelector('a[href^=\"mailto:\"]');\n",
    "                    if (emailLink) {\n",
    "                        email = emailLink.href.replace('mailto:', '').trim().toLowerCase();\n",
    "                    }\n",
    "                    \n",
    "                    // Website - links starting with // or http (excluding stb.gov.sg)\n",
    "                    let website = null;\n",
    "                    const allLinks = card.querySelectorAll('a[href^=\"//\"], a[href^=\"http\"]');\n",
    "                    for (const link of allLinks) {\n",
    "                        const href = link.getAttribute('href');\n",
    "                        if (href && !href.includes('stb.gov.sg')) {\n",
    "                            website = href.startsWith('//') ? 'https:' + href : href;\n",
    "                            break;\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    // Only add if we have a company name\n",
    "                    if (companyName) {\n",
    "                        results.push({\n",
    "                            company_name: companyName,\n",
    "                            address: address,\n",
    "                            email: email,\n",
    "                            phone: phone,\n",
    "                            website: website,\n",
    "                            license_id: licenseId,\n",
    "                            license_type: licenseType\n",
    "                        });\n",
    "                    }\n",
    "                } catch (e) {\n",
    "                    // Skip card on error\n",
    "                }\n",
    "            });\n",
    "            \n",
    "            return results;\n",
    "        });\n",
    "        \n",
    "        return { \n",
    "            status: 'success', \n",
    "            pageIndex, \n",
    "            agents, \n",
    "            count: agents.length\n",
    "        };\n",
    "        \n",
    "    } catch (err) {\n",
    "        return { status: 'error', pageIndex, error: err.message, agents: [] };\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def generate_page_urls(start_page: int, end_page: int) -> list:\n",
    "    \"\"\"Generate URLs for a range of pages\"\"\"\n",
    "    base_url = \"https://trust.stb.gov.sg/site/content/tagaem/landing-page/travel-agent.html\"\n",
    "    return [\n",
    "        {\"url\": f\"{base_url}?service=ALL&type=ALL&status=TA_A&curIndex={i}\", \n",
    "         \"userData\": {\"pageIndex\": i}}\n",
    "        for i in range(start_page, end_page)\n",
    "    ]\n",
    "\n",
    "def run_batch(client, start_urls: list, batch_num: int) -> tuple:\n",
    "    \"\"\"Run a batch of pages through Apify with concurrency - COST OPTIMIZED\"\"\"\n",
    "    \n",
    "    run_input = {\n",
    "        \"startUrls\": start_urls,\n",
    "        \"useChrome\": False,\n",
    "        \"headless\": True,\n",
    "        \"stealth\": False,\n",
    "        \"pageFunction\": create_stb_pagefunction_optimized(),\n",
    "        \"maxRequestRetries\": MAX_RETRIES,\n",
    "        \"maxRequestsPerCrawl\": len(start_urls),\n",
    "        \"maxConcurrency\": MAX_CONCURRENCY,\n",
    "        \"memoryMbytes\": 2048,\n",
    "        \"pageLoadTimeoutSecs\": 30,\n",
    "        \"pageFunctionTimeoutSecs\": 60,\n",
    "        \"waitUntil\": [\"domcontentloaded\"],\n",
    "        \"proxyConfiguration\": {\"useApifyProxy\": True},\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n[Batch {batch_num}] Starting {len(start_urls)} pages with concurrency={MAX_CONCURRENCY}\")\n",
    "    \n",
    "    try:\n",
    "        run = client.actor(\"apify/puppeteer-scraper\").call(run_input=run_input)\n",
    "        run_client = client.run(run[\"id\"])\n",
    "        run_info = run_client.wait_for_finish()\n",
    "        \n",
    "        print(f\"[Batch {batch_num}] Actor status: {run_info.get('status')}\")\n",
    "        \n",
    "        if run_info.get('status') == \"SUCCEEDED\":\n",
    "            dataset = client.dataset(run[\"defaultDatasetId\"])\n",
    "            items = list(dataset.iterate_items())\n",
    "            return items, None\n",
    "        return [], f\"Failed: {run_info.get('status')}\"\n",
    "    except Exception as e:\n",
    "        return [], str(e)\n",
    "\n",
    "def run_full_scrape(client, start_page: int, total_pages: int, batch_size: int):\n",
    "    \"\"\"Run full scrape with batching\"\"\"\n",
    "    \n",
    "    all_agents = []\n",
    "    failed_pages = []\n",
    "    batch_num = 0\n",
    "    \n",
    "    end_page = start_page + total_pages\n",
    "    \n",
    "    for batch_start in range(start_page, end_page, batch_size):\n",
    "        batch_num += 1\n",
    "        batch_end = min(batch_start + batch_size, end_page)\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"BATCH {batch_num}: Pages {batch_start} to {batch_end - 1}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        start_urls = generate_page_urls(batch_start, batch_end)\n",
    "        items, error = run_batch(client, start_urls, batch_num)\n",
    "        \n",
    "        if error:\n",
    "            print(f\"[Batch {batch_num}] ERROR: {error}\")\n",
    "            failed_pages.extend(range(batch_start, batch_end))\n",
    "        else:\n",
    "            batch_agents = 0\n",
    "            for item in items:\n",
    "                if item.get('status') == 'success':\n",
    "                    agents = item.get('agents', [])\n",
    "                    all_agents.extend(agents)\n",
    "                    batch_agents += len(agents)\n",
    "                else:\n",
    "                    page_idx = item.get('pageIndex', 'unknown')\n",
    "                    print(f\"  Page {page_idx} failed: {item.get('error', 'unknown')}\")\n",
    "                    if page_idx != 'unknown':\n",
    "                        failed_pages.append(page_idx)\n",
    "            \n",
    "            print(f\"[Batch {batch_num}] Extracted {batch_agents} agents\")\n",
    "        \n",
    "        print(f\"Running total: {len(all_agents)} agents\")\n",
    "    \n",
    "    return all_agents, failed_pages\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN FULL SCRAPE\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STB TRAVEL AGENT SCRAPER - COST OPTIMIZED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  - Start page: {START_PAGE}\")\n",
    "print(f\"  - Total pages: {TOTAL_PAGES}\")\n",
    "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  - Concurrency: {MAX_CONCURRENCY}\")\n",
    "print(f\"  - Total batches: {(TOTAL_PAGES + BATCH_SIZE - 1) // BATCH_SIZE}\")\n",
    "print(f\"  - Memory: 2048 MB (optimized)\")\n",
    "print(f\"  - Proxy: Default Apify proxy\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "all_agents, failed_pages = run_full_scrape(client, START_PAGE, TOTAL_PAGES, BATCH_SIZE)\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "# ============================================================\n",
    "# RESULTS - SAVE TO DATAFRAME\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SCRAPE COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total agents extracted: {len(all_agents)}\")\n",
    "print(f\"Failed pages: {len(failed_pages)}\")\n",
    "print(f\"Duration: {duration}\")\n",
    "\n",
    "if failed_pages:\n",
    "    print(f\"Failed page indices: {failed_pages}\")\n",
    "\n",
    "if all_agents:\n",
    "    # Create DataFrame and remove duplicates\n",
    "    stb_travel_agents_df = pd.DataFrame(all_agents)\n",
    "    stb_travel_agents_df = stb_travel_agents_df.drop_duplicates(\n",
    "        subset=['company_name', 'license_id'], \n",
    "        keep='first'\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Unique agents (after dedup): {len(stb_travel_agents_df)}\")\n",
    "else:\n",
    "    stb_travel_agents_df = pd.DataFrame()\n",
    "    print(\"No data extracted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ddd2462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>address</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>license_id</th>\n",
       "      <th>license_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GLOBE TRAVEL PTE. LTD.</td>\n",
       "      <td>111 NORTH BRIDGE ROAD #07-09 PENINSULA PLAZA S...</td>\n",
       "      <td>globetrvlsg@gmail.com</td>\n",
       "      <td>+6588047861</td>\n",
       "      <td>None</td>\n",
       "      <td>TA03459</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLOBETROTTERS' PREMIUM TRAVEL CLUB PTE. LTD.</td>\n",
       "      <td>2 SEMBAWANG WALK #01-49 SPRINGHILL SINGAPORE 7...</td>\n",
       "      <td>globetrotter.premium.travel.club@gmail.com</td>\n",
       "      <td>+6580570586</td>\n",
       "      <td>None</td>\n",
       "      <td>TA03864</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GLOBYA PTE. LTD.</td>\n",
       "      <td>703 HOUGANG AVENUE 2 #12-199 SINGAPORE 530703</td>\n",
       "      <td>globya.sg@gmail.com</td>\n",
       "      <td>+6591992302</td>\n",
       "      <td>https://www.globya.info%20</td>\n",
       "      <td>TA03519</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLOREE TOURS AND TRAVELS PTE. LTD.</td>\n",
       "      <td>50 CHIN SWEE ROAD #06-04 THONG CHAI BUILDING S...</td>\n",
       "      <td>info@gloree.com</td>\n",
       "      <td>+6568444666</td>\n",
       "      <td>https://www.gloree.com</td>\n",
       "      <td>TA01867</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLORY TRAVEL AND TOURS PTE. LTD.</td>\n",
       "      <td>101 UPPER CROSS STREET #04-48 PEOPLE'S PARK CE...</td>\n",
       "      <td>mrahim@glorytravelsg.com</td>\n",
       "      <td>+6591070573</td>\n",
       "      <td>None</td>\n",
       "      <td>TA03786</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>SUPREME TRAVEL &amp; TOURS PTE. LTD.</td>\n",
       "      <td>60 EU TONG SEN STREET #03-05 FURAMA CITY CENTR...</td>\n",
       "      <td>sales@supremetravel.com.sg</td>\n",
       "      <td>+6597888044</td>\n",
       "      <td>None</td>\n",
       "      <td>TA01664</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>SUST TRAVEL PTE. LTD.</td>\n",
       "      <td>25 DAIRY FARM ROAD #03-01 SINGAPORE 679047</td>\n",
       "      <td>daniel@susttravel.com</td>\n",
       "      <td>+6587818263</td>\n",
       "      <td>None</td>\n",
       "      <td>TA03675</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>SWISH TRAVEL PTE. LTD.</td>\n",
       "      <td>101 UPPER CROSS STREET #06-09 PEOPLE'S PARK CE...</td>\n",
       "      <td>admin@swish.sg</td>\n",
       "      <td>+6565385557</td>\n",
       "      <td>None</td>\n",
       "      <td>TA03218</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>SYUKRAN TRAVEL PTE. LTD.</td>\n",
       "      <td>101 JOO CHIAT ROAD #03-01/02 GV BUILDING SINGA...</td>\n",
       "      <td>admin@syukrantravel.com</td>\n",
       "      <td>+6569048436</td>\n",
       "      <td>None</td>\n",
       "      <td>TA03183</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>T&amp;J HOLIDAYS PTE. LTD.</td>\n",
       "      <td>9 TEMASEK BOULEVARD #07-10 (DR10) SUNTEC TOWER...</td>\n",
       "      <td>booking@tjholidays.com</td>\n",
       "      <td>+6581777585</td>\n",
       "      <td>None</td>\n",
       "      <td>TA03592</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1237 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      company_name  \\\n",
       "0                           GLOBE TRAVEL PTE. LTD.   \n",
       "1     GLOBETROTTERS' PREMIUM TRAVEL CLUB PTE. LTD.   \n",
       "2                                 GLOBYA PTE. LTD.   \n",
       "3               GLOREE TOURS AND TRAVELS PTE. LTD.   \n",
       "4                 GLORY TRAVEL AND TOURS PTE. LTD.   \n",
       "...                                            ...   \n",
       "1232              SUPREME TRAVEL & TOURS PTE. LTD.   \n",
       "1233                         SUST TRAVEL PTE. LTD.   \n",
       "1234                        SWISH TRAVEL PTE. LTD.   \n",
       "1235                      SYUKRAN TRAVEL PTE. LTD.   \n",
       "1236                        T&J HOLIDAYS PTE. LTD.   \n",
       "\n",
       "                                                address  \\\n",
       "0     111 NORTH BRIDGE ROAD #07-09 PENINSULA PLAZA S...   \n",
       "1     2 SEMBAWANG WALK #01-49 SPRINGHILL SINGAPORE 7...   \n",
       "2         703 HOUGANG AVENUE 2 #12-199 SINGAPORE 530703   \n",
       "3     50 CHIN SWEE ROAD #06-04 THONG CHAI BUILDING S...   \n",
       "4     101 UPPER CROSS STREET #04-48 PEOPLE'S PARK CE...   \n",
       "...                                                 ...   \n",
       "1232  60 EU TONG SEN STREET #03-05 FURAMA CITY CENTR...   \n",
       "1233         25 DAIRY FARM ROAD #03-01 SINGAPORE 679047   \n",
       "1234  101 UPPER CROSS STREET #06-09 PEOPLE'S PARK CE...   \n",
       "1235  101 JOO CHIAT ROAD #03-01/02 GV BUILDING SINGA...   \n",
       "1236  9 TEMASEK BOULEVARD #07-10 (DR10) SUNTEC TOWER...   \n",
       "\n",
       "                                           email        phone  \\\n",
       "0                          globetrvlsg@gmail.com  +6588047861   \n",
       "1     globetrotter.premium.travel.club@gmail.com  +6580570586   \n",
       "2                            globya.sg@gmail.com  +6591992302   \n",
       "3                                info@gloree.com  +6568444666   \n",
       "4                       mrahim@glorytravelsg.com  +6591070573   \n",
       "...                                          ...          ...   \n",
       "1232                  sales@supremetravel.com.sg  +6597888044   \n",
       "1233                       daniel@susttravel.com  +6587818263   \n",
       "1234                              admin@swish.sg  +6565385557   \n",
       "1235                     admin@syukrantravel.com  +6569048436   \n",
       "1236                      booking@tjholidays.com  +6581777585   \n",
       "\n",
       "                         website license_id license_type  \n",
       "0                           None    TA03459      General  \n",
       "1                           None    TA03864      General  \n",
       "2     https://www.globya.info%20    TA03519      General  \n",
       "3         https://www.gloree.com    TA01867      General  \n",
       "4                           None    TA03786      General  \n",
       "...                          ...        ...          ...  \n",
       "1232                        None    TA01664      General  \n",
       "1233                        None    TA03675      General  \n",
       "1234                        None    TA03218      General  \n",
       "1235                        None    TA03183      General  \n",
       "1236                        None    TA03592      General  \n",
       "\n",
       "[1237 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stb_travel_agents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b50183",
   "metadata": {},
   "outputs": [],
   "source": [
    "stb_travel_agents_df.to_csv('stb_travel_agents.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93760d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1237, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stb_travel_agents_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5af294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CHECK TOTAL PAGES - IMPROVED VERSION\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import re\n",
    "# import time\n",
    "\n",
    "# def check_stb_total_pages_v2():\n",
    "#     \"\"\"Check total pages - improved version with more detection methods\"\"\"\n",
    "    \n",
    "#     url = \"https://trust.stb.gov.sg/site/content/tagaem/landing-page/travel-agent.html?service=ALL&type=ALL&status=TA_A&curIndex=0\"\n",
    "    \n",
    "#     print(\"Launching browser...\")\n",
    "    \n",
    "#     options = Options()\n",
    "#     options.add_argument('--headless')\n",
    "#     options.add_argument('--disable-gpu')\n",
    "#     options.add_argument('--no-sandbox')\n",
    "    \n",
    "#     driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "#     try:\n",
    "#         driver.get(url)\n",
    "        \n",
    "#         # Wait for page to load\n",
    "#         WebDriverWait(driver, 20).until(\n",
    "#             EC.presence_of_element_located((By.CSS_SELECTOR, '.box-list.grid'))\n",
    "#         )\n",
    "        \n",
    "#         # Scroll to bottom to trigger lazy-loaded pagination\n",
    "#         driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#         time.sleep(2)\n",
    "        \n",
    "#         # Count cards\n",
    "#         cards = driver.find_elements(By.CSS_SELECTOR, '.box-list.grid')\n",
    "#         cards_count = len(cards)\n",
    "        \n",
    "#         # Get full page HTML and text\n",
    "#         page_html = driver.page_source\n",
    "#         page_text = driver.find_element(By.TAG_NAME, 'body').text\n",
    "        \n",
    "#         print(f\"\\n{'='*50}\")\n",
    "#         print(\"PAGINATION INFO:\")\n",
    "#         print(f\"{'='*50}\")\n",
    "#         print(f\"Cards on first page: {cards_count}\")\n",
    "        \n",
    "#         # Method 1: Look for any number patterns in text\n",
    "#         # Common patterns: \"1500 results\", \"Page 1 of 100\", \"Showing 1-15 of 1500\"\n",
    "#         patterns = [\n",
    "#             r'(\\d[\\d,]*)\\s*(?:results?|records?|entries|items|agents?)',\n",
    "#             r'page\\s*\\d+\\s*of\\s*(\\d+)',\n",
    "#             r'showing\\s*\\d+\\s*-\\s*\\d+\\s*of\\s*([\\d,]+)',\n",
    "#             r'total[:\\s]*(\\d[\\d,]*)',\n",
    "#         ]\n",
    "        \n",
    "#         for pattern in patterns:\n",
    "#             match = re.search(pattern, page_text, re.IGNORECASE)\n",
    "#             if match:\n",
    "#                 total = int(match.group(1).replace(',', ''))\n",
    "#                 print(f\"Found total: {total} (pattern: {pattern[:30]}...)\")\n",
    "#                 if cards_count > 0:\n",
    "#                     estimated_pages = (total + cards_count - 1) // cards_count\n",
    "#                     print(f\"Estimated pages: {estimated_pages}\")\n",
    "#                 break\n",
    "        \n",
    "#         # Method 2: Look for pagination elements\n",
    "#         pagination_selectors = [\n",
    "#             '.pagination a',\n",
    "#             '.pager a', \n",
    "#             'a[href*=\"curIndex\"]',\n",
    "#             'a[href*=\"page=\"]',\n",
    "#             'button[data-page]',\n",
    "#             '.page-numbers',\n",
    "#             'nav[aria-label*=\"pagination\"] a',\n",
    "#             'ul.pagination li a'\n",
    "#         ]\n",
    "        \n",
    "#         max_page = 0\n",
    "#         for selector in pagination_selectors:\n",
    "#             try:\n",
    "#                 elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "#                 for el in elements:\n",
    "#                     text = el.text.strip()\n",
    "#                     href = el.get_attribute('href') or ''\n",
    "                    \n",
    "#                     # Check text for numbers\n",
    "#                     if text.isdigit():\n",
    "#                         max_page = max(max_page, int(text))\n",
    "                    \n",
    "#                     # Check href for page indices\n",
    "#                     for param in ['curIndex', 'page', 'p']:\n",
    "#                         match = re.search(rf'{param}[=:](\\d+)', href)\n",
    "#                         if match:\n",
    "#                             max_page = max(max_page, int(match.group(1)))\n",
    "#             except:\n",
    "#                 pass\n",
    "        \n",
    "#         if max_page > 0:\n",
    "#             print(f\"Max page from pagination: {max_page}\")\n",
    "        \n",
    "#         # Method 3: Check for \"next\" or \"last\" buttons\n",
    "#         last_selectors = ['a[title*=\"last\"]', 'a[aria-label*=\"last\"]', '.last a', 'a:contains(\"Â»\")']\n",
    "#         for selector in last_selectors:\n",
    "#             try:\n",
    "#                 el = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "#                 href = el.get_attribute('href') or ''\n",
    "#                 match = re.search(r'curIndex=(\\d+)', href)\n",
    "#                 if match:\n",
    "#                     print(f\"Last page index: {match.group(1)}\")\n",
    "#             except:\n",
    "#                 pass\n",
    "        \n",
    "#         # Method 4: Print sample of page text for manual inspection\n",
    "#         print(f\"\\n--- Sample page text (first 500 chars) ---\")\n",
    "#         print(page_text[:500])\n",
    "        \n",
    "#         return {\"cards_per_page\": cards_count}\n",
    "        \n",
    "#     finally:\n",
    "#         driver.quit()\n",
    "#         print(\"\\n\\nBrowser closed.\")\n",
    "\n",
    "# # Run\n",
    "# pagination_info = check_stb_total_pages_v2()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
